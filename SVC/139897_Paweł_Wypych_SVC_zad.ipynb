{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Przygotowanie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przygotowanie\n",
    "Przed rozpoczęciem pracy z notatnikiem proszę zmienić jego nazwę dodając na początku numer albumu, imię i nazwisko. {nr_albumu}_{imię}_{nazwisko}_{nazwa}\n",
    "\n",
    "Po wykonaniu wszystkich zadań proszę przesłać wypełniony notatnik przez platformę ELF za pomocą formularza \"Prześlij projekt\" w odpowiedniej sekcji."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jest to jeden z najbardziej rozpowszechnionych i wszechstronnych modeli uczenia maszynowego. Z jego uzyciem dokonac mozna klasyfikacji liniowej (SVC), nieliniowej jak i regresji (SVR). Na poniższej grafice przedstawione zostało działanie klasyfikatora."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![svc](svc.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizujac grafike dostrzec mozna dwie oddzielne klasy oddzielone za pomoca prostej. Widoczna linia ciagła rozdziela klasy, a przerywane linie oznaczają margines, czyli możliwe najdalsze oddalenie elementu (np. nowego) jaki zakwalifikowany\n",
    "zostanie do danej klasy. Maszyny SVM czułe sa na skale danych, przed ich uzyciem zawsze powinna zostać przeprowadzona normalizacja danych (np. min-max, lub standaryzacja).\n",
    "\n",
    "![svc_example](svc2.jpg)\n",
    "\n",
    "Równowage pomiedzy marginesami możemy regulować za pomoca hipermarapetru\n",
    "C. Mniejsze jego wartości poszerzają granice, jednocześnie wprowadzając\n",
    "więcej jej naruszeń. Im margines jest szerszy, tym własciwosci generalizujace\n",
    "jakie posiada klasyfikator będę większe. Mniejsza staje się podatność na przeuczenie\n",
    "(ang. overfitting), ale zmniejsza się skuteczność klasyfikatora. Szukany jest\n",
    "taki klasyfikator, który podzieli przestrzeń na dwa rozłaczne zbiory odpowiadajace\n",
    "dwóm klasom, w możliwie optymalny sposób. Podejście opiera się na\n",
    "znalezieniu granicy decyzyjnej.\n",
    "\n",
    "Wektory nośne (Support vectors) są to obserwacje (data points), które wystepują najbliżej hiperpłaszczyzny. Punkty te, pomagają lepiej wyznaczyć linię separacji pomiędzy klasami poprzez obliczenie marginesów. Są to najbardziej znaczace obserwacje ze zbioru z punktu widzenia konstrukcji klasyfikatora.\n",
    "\n",
    "Warto zaznaczyć, że za pomocą klasyfikatora SVC można klasyfikaować dane, które nie są linowo separowalne. Można to osiągnąć przez tzw \"sztuczkę kernelową\", dzięki czemu możliwe jest zmapowanie obserwacji do wielowymiarowej przestrzeni. Klasyfikator z biblioteki Sklearn posiada parametr *kernel*, który pozwala na zmianę jądra. Dodatkowo, parametr *gamma* pozwala na modyfikację działania samego kernela.\n",
    "\n",
    "Warto zaznaczyć, że SVC dobrze nadaje się do niewielkich zbiorów danych, gdyż w przypadku dużej ilości staję się on mało wydajny."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcja jaka jest minimalizowana podczas działania klasyfikatora wygląda następująco:\n",
    "\n",
    "\\begin{equation}\n",
    "min C \\sum^m_{i=1}[y^{(i)}cost_{1}(\\theta^{T}x^{(i)}) - (1 - y^{(i)})cost_{0}(\\theta^{T}x^{(i)})] + \\frac{1}{2} \\sum^{n}_{i=1}\\theta^{2}_{j}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wczytanie danych ze zbioru oraz wizualizacja."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "from pandas.core.interchange.dataframe_protocol import DataFrame\n",
    "\n",
    "data_input = pd.read_csv('./Ankieta.csv')\n",
    "data_input.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "\n",
    "x = data_input['plec'].map(lambda x: 1 if x == 'Kobieta' else 0)\n",
    "y = data_input['waga']\n",
    "z = data_input['wzrost']\n",
    "\n",
    "data_input['plec'] = data_input['plec'].map(lambda x: 1 if x == 'Kobieta' else 0)\n",
    "\n",
    "plt.scatter(y, z, c=x, cmap=colors.ListedColormap(['red', 'green']))\n",
    "plt.xlabel('waga')\n",
    "plt.ylabel('wzrost')\n",
    "plt.title('Ankieta')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize = (10,10))\n",
    "ax = fig.gca()\n",
    "data_input.hist(ax=ax)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "data_input.boxplot()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na bazie wykresów box-plot można stwierdzić, że dane posiadają różniące się zakresy, co powoduje potrzebę ich skalowania. Warto zauważyć również, że rozkład klas w zbiorze jest równomierny (patrz: histogram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proszę dokonać normalizacji zbioru danych za pomocą standaryzacji oraz narysować wykres box-plot dla wszystkich zmiennych. W jaki sposób zmieniły się dane? Co można powiedzieć o ich zakresach. W jakim celu dokonujemy normalizacji?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(data_input)\n",
    "std_data_input = scaler.transform(data_input)\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "x = std_data_input[:,0]\n",
    "y = std_data_input[:,1]\n",
    "z = std_data_input[:,2]\n",
    "plt.scatter(x[z == 1], y[z == 1],c='blue',label=\"woman\")\n",
    "plt.scatter(x[z == 0], y[z == 0],c='red',label=\"men\")\n",
    "plt.xlabel(\"weight\")\n",
    "plt.ylabel(\"height\")\n",
    "plt.title(\"normalized data\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "std_data_input_df = pd.DataFrame(std_data_input, columns=[\"waga\", \"wzrost\", \"plec\"])\n",
    "\n",
    "fig2, ax2 = plt.subplots(figsize=(8,8))\n",
    "std_data_input_df.hist()\n",
    "\n",
    "fig3, ax3 = plt.subplots(figsize=(8,8))\n",
    "std_data_input_df.boxplot(ax=ax3)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W tym zadaniu należy dokonać podziału zbioru danych na uczący oraz testowy. Zbiór uczący będzie służył do treningu klasyfikatora, a testowy do obliczenia ostatecznej skuteczności klasyfikacji. Prosze, by 80% próbek znalazło się w zbiorze uczącym, a 20% w testowym. Proszę zadbać o odpowiednią inicjalizacje generatora pseudolosowego"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "training_data_st, testing_data_st = train_test_split(std_data_input_df,\n",
    "                                               test_size=0.2,\n",
    "                                               train_size=0.8,\n",
    "                                               random_state=23)\n",
    "\n",
    "training_data, testing_data = train_test_split(data_input,\n",
    "                                               test_size=0.2,\n",
    "                                               train_size=0.8,\n",
    "                                               random_state=23)\n",
    "\n",
    "print(training_data_st.shape)\n",
    "print(testing_data_st.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W tym zadaniu należy dokonać klasyfikacji danych za pomocą klasyfikatora SVC. Proszę obliczyć skuteczność klasyfikatora na danych po, oraz przed standaryzacją i porównać wyniki."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "svc_st = SVC(kernel=\"rbf\", gamma='scale', C=1, random_state=23)\n",
    "svc = SVC(kernel=\"rbf\", gamma='scale', C=1, random_state=23)\n",
    "svc_st.fit(training_data_st[[\"waga\",\"wzrost\"]], training_data_st[\"plec\"])\n",
    "svc.fit(training_data[[\"waga\",\"wzrost\"]], training_data[\"plec\"])\n",
    "\n",
    "y_pred_st = svc_st.predict(testing_data_st[[\"waga\",\"wzrost\"]])\n",
    "y_pred = svc.predict(testing_data[[\"waga\",\"wzrost\"]])\n",
    "print(\"Accuracy before data standarization:\", accuracy_score(testing_data[\"plec\"], y_pred))\n",
    "print(\"Accuracy after data standarization:\", accuracy_score(testing_data_st[\"plec\"], y_pred_st))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proszę dobrać odpowiedni parametr C (proszę spróbować z zakresu 0, 5 z krokiem co 0.5). Dla każdego C proszę wyrysować hiperpłaszczyznę utworzoną przez klasyfikator (w formie animimacji, lub inaczej). Proszę przedstawić na wykresie jak zmieniała się skuteczność klasyfikatora w zależności od parametru C. Jakie wnioski można wyciągnąć? Jak wpływa parametr C na wynik?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "c_params = np.arange(0.01,5.1,0.5)\n",
    "print(c_params)\n",
    "\n",
    "xx, yy = np.meshgrid(np.linspace(0, 1, 100), np.linspace(0, 1, 100))\n",
    "\n",
    "for c in c_params:\n",
    "    # Train SVM\n",
    "    svc_st = SVC(kernel=\"rbf\", gamma='scale', C=c, random_state=42)\n",
    "    svc_st.fit(training_data_st[[\"waga\", \"wzrost\"]], training_data_st[\"plec\"])\n",
    "\n",
    "    # Predict on test set\n",
    "    y_pred_st = svc_st.predict(testing_data_st[[\"waga\", \"wzrost\"]])\n",
    "    acc = accuracy_score(testing_data_st[\"plec\"], y_pred_st)\n",
    "    print(f\"Accuracy for C = {c} after standardization: {acc:.4f}\")\n",
    "\n",
    "    # Predict on meshgrid for visualization\n",
    "    grid_points = pd.DataFrame(np.c_[xx.ravel(), yy.ravel()], columns=[\"waga\", \"wzrost\"])\n",
    "    Z = svc_st.predict(grid_points)\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    # Separate men and women for coloring\n",
    "    men = testing_data_st[testing_data_st[\"plec\"] == 0]\n",
    "    women = testing_data_st[testing_data_st[\"plec\"] == 1]\n",
    "\n",
    "    # Create scatter plot for men (red)\n",
    "    scatter_men = go.Scatter3d(\n",
    "        x=men[\"waga\"],\n",
    "        y=men[\"wzrost\"],\n",
    "        z=men[\"plec\"],\n",
    "        mode='markers',\n",
    "        marker=dict(size=5, color='red', opacity=0.8),\n",
    "        name=\"Men\"\n",
    "    )\n",
    "\n",
    "    # Create scatter plot for women (blue)\n",
    "    scatter_women = go.Scatter3d(\n",
    "        x=women[\"waga\"],\n",
    "        y=women[\"wzrost\"],\n",
    "        z=women[\"plec\"],\n",
    "        mode='markers',\n",
    "        marker=dict(size=5, color='blue', opacity=0.8),\n",
    "        name=\"Women\"\n",
    "    )\n",
    "\n",
    "    # Create 3D surface plot for decision boundary\n",
    "    surface = go.Surface(z=Z, x=xx, y=yy, opacity=0.7, colorscale=\"RdBu\", showscale=False)\n",
    "\n",
    "    # Combine all plots\n",
    "    fig = go.Figure(data=[surface, scatter_men, scatter_women])\n",
    "    fig.update_layout(\n",
    "        title=f\"SVM Classification (C = {c})\",\n",
    "        scene=dict(\n",
    "            xaxis_title=\"Weight (waga)\",\n",
    "            yaxis_title=\"Height (wzrost)\",\n",
    "            zaxis_title=\"Predicted Class (plec)\"\n",
    "        ),\n",
    "        legend=dict(x=0, y=1)  # Position legend at the top-left\n",
    "    )\n",
    "    # Show interactive chart\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "'''Dla małych wartości parametru C, algorytm pozwala na większą tolerancję błędów ale lepiej generalizuje, dzięki czemu otrzymujemy większym margines. Dla dużych wartości C algorytm próbuje zklasyfikować wszystkie próbki prawidłowo przez co otrzymujemy wąski margines oraz mniejszą tolerancję błędów.'''"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proszę dokonać pomiaru czasu wykonania algorytmu dla min. 2 różnych kerneli"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import timeit\n",
    "\n",
    "def train_svc_function(kernel):\n",
    "    svc_st = SVC(kernel=kernel, gamma='scale', C=c, random_state=42)\n",
    "    svc_st.fit(training_data_st[[\"waga\", \"wzrost\"]], training_data_st[\"plec\"])\n",
    "\n",
    "    y_pred_st = svc_st.predict(testing_data_st[[\"waga\", \"wzrost\"]])\n",
    "    accuracy_score(testing_data_st[\"plec\"], y_pred_st)\n",
    "\n",
    "execution_time = timeit.timeit(lambda: train_svc_function(\"rbf\"), number=500)\n",
    "print(f\"Execution time: {execution_time:.4f} seconds for kernel: rbf\")\n",
    "execution_time = timeit.timeit(lambda: train_svc_function(\"poly\"), number=500)\n",
    "print(f\"Execution time: {execution_time:.4f} seconds for kernel: poly\")\n",
    "execution_time = timeit.timeit(lambda: train_svc_function(\"sigmoid\"), number=500)\n",
    "print(f\"Execution time: {execution_time:.4f} seconds for kernel: sigmoid\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analiza wektorów nośnych (support vectors). Wyodrębnij wektory nośne z wytrenowanego modelu używając właściwości `.support_vectors_`. Zwizualizuj położenie wektorów nośnych na wykresie, jaki procent danych stanowią wektory nośne?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "svc_st = SVC(kernel=\"rbf\", gamma='scale', C=1, random_state=42)\n",
    "svc_st.fit(training_data_st[[\"waga\", \"wzrost\"]], training_data_st[\"plec\"])\n",
    "\n",
    "s_vectors = svc_st.support_vectors_\n",
    "\n",
    "total_samples = len(training_data_st)\n",
    "num_support_vectors = len(s_vectors)\n",
    "percentage_support_vectors = (num_support_vectors / total_samples) * 100\n",
    "print(f\"Support vectors represent {percentage_support_vectors:.2f}% of the data.\")\n",
    "\n",
    "# Plot the data points and support vectors\n",
    "plt.scatter(training_data_st['waga'], training_data_st['wzrost'], c=training_data_st['plec'], cmap='coolwarm', label=\"Data Points\")\n",
    "plt.scatter(s_vectors[:, 0], s_vectors[:, 1], color='black', marker='x', s=100, label=\"Support Vectors\")\n",
    "\n",
    "plt.xlabel(\"Weight\")\n",
    "plt.ylabel(\"Height\")\n",
    "plt.title(\"Support Vectors in SVM\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dla zbioru *dataR2* proszę dokonać podobnej analizy danych. Opis zbioru: https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Coimbra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proszę zwizualizować dane dla 2 dowolnych zmiennych ze zbioru"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "data = pd.read_csv(\"dataR2.csv\")\n",
    "# Classification = 1 (Healthy)  / 2 (Patient)\n",
    "data = data[[\"Glucose\", \"Resistin\", \"Classification\"]]\n",
    "glucose = data[\"Glucose\"]\n",
    "resistin = data[\"Resistin\"]\n",
    "classification = data[\"Classification\"]\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.scatter(glucose[classification == 1], resistin[classification == 1], c = \"green\" ,label= \"Healthy\")\n",
    "plt.scatter(glucose[classification == 2], resistin[classification == 2], c = \"red\" ,label= \"Patient\")\n",
    "plt.xlabel(\"Glucose\")\n",
    "plt.ylabel(\"Resistin\")\n",
    "plt.title(\"Breast cancer correlation between Glucose and Resistin\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proszę dokonać standaryzacji danych"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(data)\n",
    "std_data = scaler.transform(data)\n",
    "std_data = pd.DataFrame(std_data, columns=[\"Glucose\", \"Resistin\", \"Classification\"])\n",
    "std_glu = std_data[\"Glucose\"]\n",
    "std_resi = std_data[\"Resistin\"]\n",
    "fig = plt.figure()\n",
    "plt.scatter(std_glu[classification == 1], std_resi[classification == 1], c = \"green\" ,label= \"Healthy\")\n",
    "plt.scatter(std_glu[classification == 2], std_resi[classification == 2], c = \"red\" ,label= \"Patient\")\n",
    "plt.xlabel(\"Glucose\")\n",
    "plt.ylabel(\"Resistin\")\n",
    "plt.title(\"Breast cancer correlation between Glucose and Resistin\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trenowanie klasyfikatora. Proszę dokonać treningu klasyfikatora na zbiorze treningowym (X_train, y_train). Proszę użyć różnych wartości parametru C, gamma oraz kernel. Pełna dokumentacja klasyfikatora: https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html Wyniki proszę podsumować na odpowiednim wykresie lub tabeli. Test skuteczności klasyfikatora proszę dokonać na zbiorze testowym (X_test, y_test)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "training_data, testing_data = train_test_split(std_data,\n",
    "                                                test_size=0.2,\n",
    "                                                random_state=24)\n",
    "\n",
    "c_params = [0.01, 0.1, 1, 10]\n",
    "gamma_params = [0.01, 0.1, 1, 10]\n",
    "kernels = [\"rbf\",\"sigmoid\",\"poly\"]\n",
    "results = []\n",
    "\n",
    "for kern in kernels:\n",
    "    for c in c_params:\n",
    "        for g in gamma_params:\n",
    "            svc = SVC(C=c, kernel=kern, gamma=g)\n",
    "            svc.fit(training_data[[\"Glucose\",\"Resistin\"]], training_data[\"Classification\"])\n",
    "            y_predict = svc.predict(testing_data[[\"Glucose\",\"Resistin\"]])\n",
    "            acc = accuracy_score(testing_data[\"Classification\"], y_predict)\n",
    "            #print(f\"Accuracy: {acc:.3f} for kernel: {kern} C: {c} gamma: {g}\")\n",
    "            result = {\n",
    "                \"kernel\": kern,\n",
    "                \"gamma\": g,\n",
    "                \"c\": c,\n",
    "                \"accuracy\": acc\n",
    "            }\n",
    "            results.append(result)\n",
    "df_res = pd.DataFrame(results, columns=[\"kernel\",\"gamma\",\"c\",\"accuracy\"])\n",
    "df_res"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Należy wyznaczyć macierze pomyłek dla klasyfikatora. Proszę dokonać wizualizacji wraz z kolorami na wykresie. Przykłady: \n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "svc = SVC(C=0.1, kernel=\"rbf\", gamma=10)\n",
    "svc.fit(training_data[[\"Glucose\",\"Resistin\"]], training_data[\"Classification\"])\n",
    "y_predict = svc.predict(testing_data[[\"Glucose\",\"Resistin\"]])\n",
    "y_true = testing_data[\"Classification\"]\n",
    "cm = confusion_matrix(y_true,y_predict)\n",
    "print(y_true.shape)\n",
    "\n",
    "sns.heatmap(cm,\n",
    "            annot=True,\n",
    "            fmt=\"d\",\n",
    "            cmap=\"magma\",\n",
    "            xticklabels=[\"Negative\", \"Positive\"],\n",
    "            yticklabels=[\"Negative\", \"Positive\"],\n",
    "            annot_kws={\"color\": \"white\"},\n",
    "            linewidths=1\n",
    "            )\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-tum_py313]",
   "language": "python",
   "name": "conda-env-.conda-tum_py313-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
