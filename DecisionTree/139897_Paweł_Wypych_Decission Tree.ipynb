{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Przygotowanie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przygotowanie Przed rozpoczęciem pracy z notatnikiem proszę zmienić jego nazwę dodając na początku numer albumu, imię i nazwisko. {nr_albumu}_{imię}_{nazwisko}_{nazwa}\n",
    "\n",
    "Po wykonaniu wszystkich zadań proszę przesłać wypełniony notatnik przez platformę ELF za pomocą formularza \"Prześlij projekt\" w odpowiedniej sekcji."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drzewa decyzyjne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podobnie jak w przypadku maszyny wektorów nosnych (SVC), drzewa decyzyjne sa wszechstronnym algorytmem uczenia maszynowego. Mogą słuzyc do rozwiazywania problemów zarówno klasyfikacji, jak i regresji. W przeciwieństwie do modelu SVC drzewa decyzyjne nie wymagają restrykcyjnego przygotowania danych (np. skalowania cech). Drzewa decyzyjne składaja sie z korzenia oraz gałezi prowadzacych do kolejnych wierzchołków. W wezłach - wierzchołkach z których wychodzi co najmniej jedna krawedź, sprawdzany jest pewien warunek. Na jego podstawie, wybierana jest gałaz prowadząca do kolejnego wierzchołka. Dana obserwacja zostaje zaklasyfikowana do konkretnej klasy po przejściu od korzenia do liscia i przypisaniu do tej obserwacji klasy, z danego liscia (nie wychodza z niego wezły potomne).\n",
    "\n",
    "Za pomocą drzew decyzyjnych otrzymać możemy potężne modele zdolne do nauki złożonych zbiorów danych.\n",
    "\n",
    "###  Las losowy\n",
    "\n",
    "Klasyfikator lasu losowego jest klasyfikatorem zespołowym złozonym z drzew decyzyjnych. Klasyfikator ten wprowadza dodatkową losowość do wzrostu drzew. Nie wyszukuje on najlepszej cechy podczas podziału na wezły, ale szuka najlepszej cechy wsród losowego podziału cech. Powoduje to wieksze zróznicowanie powstałych w klasyfikatorze drzew. Losowe lasy są bardziej odporne na nadmierne dopasowanie się do zbioru treningowego, jakie spotykane jest podczas użycia drzew decyzyjnych."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, [2, 3]]\n",
    "y = iris.target\n",
    "\n",
    "print('Class labels:', np.unique(y))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "unique, counts = np.unique(y, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pydotplus import graph_from_dot_data\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "tree = DecisionTreeClassifier(criterion='gini', max_depth=2, random_state=1)\n",
    "tree.fit(X, y)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "plot_tree(tree, \n",
    "          filled=True, \n",
    "          rounded=True,\n",
    "          class_names=['Setosa', \n",
    "                       'Versicolor',\n",
    "                       'Virginica'],\n",
    "          feature_names=['petal length', \n",
    "                         'petal width']) \n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jak podejmowane są decyzje w drzewie?\n",
    "\n",
    "Klasyfikacja próbki zaczyna się zawsze od korzenia (węzeł na samej górze grafu). W węźle zadawane jest pytanie (w przykładnie powyżej czy długość płatka jest mniejsza od 0.8). Jeśli prawda przechodzimy do węzła potomnego lewego, w przeciwnym razie do prawego. Przechodząc do węzła lewego dochodzimy do **liścia** (leaf node, nie posiada węzłów potomnych) - w taki wypadku żadne pytanie nie jest zadawane, przydzielana jest już tylko klasa do danej obserwacji. \n",
    "\n",
    "W przypadku, gdy skierujemy się ku węzłowi prawemu (nie jest już liściem) zadajemy kolejne pytanie, aż dojdziemy do liścia.\n",
    "\n",
    "Znaczenie atrybutów:\n",
    "\n",
    "- *samples* - oznacza ilość wyznaczonych próbek dla danego węzła (zgadza się to w przedstawionym przypadku z ilością próbek dla danych klas)\n",
    "- *value* - określa ilość przykładów uczących z każdej klasy jakie przynależą do danego węzła.\n",
    "- *gini* - miara zanieczyszczenia węzła (0 oznacza, że wszystkie próbki w węźle należą do jednej klasy - idealna klasyfikacja)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wskaźnik Gingiego:\n",
    "    \\begin{equation*}\n",
    " G_{i} = 1 - \\sum_{k=1}^{n} p_{i, k}^{2}\n",
    "\\end{equation*}\n",
    "gdzie $p_{i,k}$ oznacza współczynie występowania klas k, wśród próbek uczących w węźle i."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jako wskaźnik zanieczyszczenia (parametr *entropy*), użyta może zostać również miara entropii. Wynosi ona 0, w przypadku, gdy wszystkie informacje są takie same - wszystkie próbiki w węźle należą do jednej klasy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entropia:\n",
    "    \n",
    "\\begin{equation*}\n",
    "    H_{i} = - \\sum_{k=1\\\\ p_{i,k} \\neq 0}^{n} p_{i, k} log(p_{i,k})\n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Różnice pomędzy tymi dwoma miarami są zazwyczaj bardzo znikome i nie wypływają znacząco na skuteczność działania klasyfikatora. Dla zainteresowanych szczegółami zapraszam do lektury: https://sebastianraschka.com/faq/docs/decision-tree-binary.html, https://towardsdatascience.com/the-simple-math-behind-3-decision-tree-splitting-criterions-85d4de2a75fe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W jakim momencie przestać budować drzewo decyzyje?\n",
    "\n",
    "Problemy rozważane w uczeniu maszynowym mają zazwyczaj sporą liczbę cech, która może powodować wysoko rosnące skomplikowanie drzewa (jego wielkość, sporą ilość węzłów oraz podziałów w węzłach). Tak utworzone drzewa mogą powodować nadmierne dopasowanie do danych treningowych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorytm drzewa decyzyjnego posiada parametry, które ustalane są podczas uczenia. Jak wspomniano, może powodować to przetrenowanie klasyfikatora (nadmierne dopasowanie do danych uczących). Aby tego uniknąć, dobrym rozwiązaniem okazuje się ograniczenie swobody działania klasyfikatora. Podobnie jak w przypadku klasyfikatora SVC, również dla drzewa decyzyjnego zdefinowane zostały parametry regularyzacyjne:\n",
    "\n",
    "- *max_depth* - maksymalna wysokość drzewa\n",
    "- *min_samples_split* - minimalna liczba próbek, jakie będą w węźle (przed podziałem)\n",
    "- *min_samples_leaf* - minimalna liczba próbek, jakie będą w liściu\n",
    "- *max_leaf_nodes* - maksymalna ilość liści\n",
    "- *max_features* - maksymalna liczba cech używana do dzielenia węzła.\n",
    "\n",
    "Modyfikacja tych parametrów powoduje regularyzację drzewa i zmniejsza ryzyko przetrenowania."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadania"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 1"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=10, criterion=\"entropy\", random_state=1)\n",
    "tree.fit(np.log(X ** 8), y)\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "labels = ['Decision Tree']\n",
    "fig = plot_decision_regions(X=np.log(X ** 8), y=y, clf=tree, legend=2)\n",
    "plt.title(\"Decision boundary\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jakie wnioski możne sformuować na bazie granic decyzyjnych przedstawionych powyżej? W momencie pojawianie się dodatkowej próbki klasy *zielonej* (2), zostanie ona dobrze sklasyfikowana? Czy klasyfikator posiada dobre właściwości generalizujące?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 1 - Próbka prawdopodobnie nie zostanie dobrze sklasyfikowana ponieważ wynik działania algorytmu wskazuje na przeuczenie.\n",
    "# 2 - Klasyfikator nie posiada dobrych właściwości generalizujących."
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proszę o wczytanie, opisanie zbioru danych: https://www.kaggle.com/datasets/mathchi/diabetes-data-set. Proszę o usunięcie danych None. Zbiór danych powinien być użyty do dalszych oblicze"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"diabetes.csv\")\n",
    "\n",
    "print(\"Total number of NaN/None values:\",data.isna().sum().sum()) # total number of NaN/ None values\n",
    "df_cleaned = data.dropna() # Get rid of rows that contain NaN values\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proszę wytrenować zbiór z użyciem algorytmu drzewa decyzyjnego. Proszę pamiętać o odpowienim podziale na zbiór uczący i treningowy. Klasyfikator powinien być trenowany na zbiorze treningowym, a wynik jego skuteczności po trenowaniu obliczany w oparciu o zbiór testowy.\n",
    "\n",
    "Proszę przygotować wyniki, trenując algorytm z użyciem różnych parametrów - należy przygotować wykresy (oś pionowa określa skuteczność, pozioma wartość parametru) pokazujące jak zmienia się skuteczność działania w zależności od zastosowanych wartości parametrów. Proszę o przygotowanie odpowiedniego porównania (tabela), co można zaobserwować?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "data_train, data_test = train_test_split(df_cleaned,\n",
    "                                         test_size=0.2)\n",
    "\n",
    "\n",
    "def train_tree_classifier(params):\n",
    "    clf = DecisionTreeClassifier(criterion=params[\"criterion\"],\n",
    "                                max_depth=params[\"max_depth\"],\n",
    "                                min_samples_split=params[\"min_samples_split\"],\n",
    "                                min_samples_leaf=params[\"min_samples_leaf\"],\n",
    "                                max_features=params[\"max_features\"],\n",
    "                                random_state=params[\"random_state\"])\n",
    "    clf = clf.fit(data_train.iloc[:,:8], data_train.iloc[:,8])\n",
    "    y_predict = clf.predict(data_test.iloc[:,:8])\n",
    "    accuracy = accuracy_score(data_test.iloc[:,8], y_predict)\n",
    "    return pd.DataFrame([{**params, \"accuracy\": accuracy}])\n",
    "\n",
    "parameters = {\"criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
    "              \"max_depth\": [2, 4, 8, 16],\n",
    "              \"min_samples_split\": [2, 4, 6, 8],\n",
    "              \"min_samples_leaf\": [1, 2, 4, 6, 10],\n",
    "              \"max_features\": [None, \"sqrt\", \"log2\", 0.5, 2, 8],\n",
    "              \"random_state\": [42]\n",
    "              }\n",
    "\n",
    "results_df = pd.DataFrame(columns=[\n",
    "    \"accuracy\", \"criterion\", \"max_depth\", \"min_samples_split\",\n",
    "    \"min_samples_leaf\", \"max_features\", \"random_state\"\n",
    "])\n",
    "\n",
    "keys, values = zip(*parameters.items())\n",
    "for combination in product(*values):\n",
    "    param_dict = dict(zip(keys, combination))\n",
    "    df = pd.DataFrame(train_tree_classifier(param_dict))\n",
    "    results_df = pd.concat([results_df, df])\n",
    "\n",
    "\n",
    "for param in parameters.keys():\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.boxplot(x=results_df[param], y=results_df[\"accuracy\"])\n",
    "    plt.xlabel(param)\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(f\"Accuracy vs {param}\")\n",
    "    plt.xticks(rotation=45)  # Rotate labels if necessary\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "results_df\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drzewa decyzyjne mogą również szacować przewdopodobieństwo przynależności danej próbki do określonej klasy. Proszę przeprowadzić odpowiednie trenowanie klasyfikatora i określić jak zmienia się prawdopodobieństwo przynależności różnych próbek. Wystarczy odnaleźć odpowienią właściwość klasyfikatora i pokazać jakie jest zwracane prawdopodobieństwo dla kilku przykładów."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "clf = DecisionTreeClassifier(criterion=\"gini\",\n",
    "                             max_depth=4,\n",
    "                             min_samples_split=6,\n",
    "                             min_samples_leaf=4,\n",
    "                             random_state=42)\n",
    "\n",
    "feature1, feature2 = 0, 1\n",
    "\n",
    "clf.fit(data_train.iloc[:, [feature1, feature2]], data_train.iloc[:, -1])\n",
    "sample_data = data_test.iloc[:, [feature1, feature2]]\n",
    "\n",
    "probabilities = clf.predict_proba(sample_data)\n",
    "\n",
    "prob_df = pd.DataFrame(probabilities, columns=[f\"Class_{c}\" for c in clf.classes_])\n",
    "prob_df[\"Actual Class\"] = data_test.iloc[:, -1].values\n",
    "\n",
    "print(prob_df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proszę wyrysować granice decyzyjne dla klasyfikatora drzewa decyzyjnego utworzonego we wcześniejszym zadaniu. Jakie można sformuować wnioski?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "feature1, feature2 = 0, 1\n",
    "X = df_cleaned.iloc[:, [feature1, feature2]].values\n",
    "y = df_cleaned.iloc[:, -1].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max, 100))\n",
    "\n",
    "Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.contourf(xx, yy, Z, alpha=0.3, cmap=\"Paired\")\n",
    "sns.scatterplot(x=X_test[:, 0], y=X_test[:, 1], hue=y_test, edgecolor=\"r\", marker=\"s\", palette=\"Paired\")\n",
    "plt.xlabel(\"Pregnancies\")\n",
    "plt.ylabel(\"Glucose\")\n",
    "plt.title(\"Decision tree decision boundaries\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "'''Model dość dobrze generalizuje, ale nie jest pozbawiony błędów. Na pewno nie jest przeuczony.'''"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proszę dokonać optymalizacji paramertrów (min. 3) modelu w oparciu o metodę przeszukiwania siatki: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {\"criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
    "              \"max_depth\": [2, 4, 8, 16],\n",
    "              \"min_samples_split\": [2, 4, 6, 8],\n",
    "              \"min_samples_leaf\": [1, 2, 4, 6, 10],\n",
    "              \"max_features\": [None, \"sqrt\", \"log2\", 0.5, 2, 8],\n",
    "              \"random_state\": [42]\n",
    "              }\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state = 42)\n",
    "grid_search = GridSearchCV(tree, parameters, scoring=\"accuracy\", cv=5)\n",
    "grid_search.fit(data_train.iloc[:,:8], data_train.iloc[:,8])\n",
    "GridSearchCV(estimator=DecisionTreeClassifier(),\n",
    "             param_grid=parameters,\n",
    "             n_jobs=-1)\n",
    "\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)\n",
    "\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "results_df[['params', 'mean_test_score', 'rank_test_score']]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-tum_py313]",
   "language": "python",
   "name": "conda-env-.conda-tum_py313-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
