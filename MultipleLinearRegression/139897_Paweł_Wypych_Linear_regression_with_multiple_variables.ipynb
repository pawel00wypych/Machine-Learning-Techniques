{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przygotowanie\n",
    "\n",
    "Przed rozpoczęciem pracy z notatnikiem proszę zmienić jego nazwę dodając na początku numer albumu, imię i nazwisko.\n",
    "{nr_albumu}\\_{imię}\\_{nazwisko}\\_{nazwa}\n",
    "\n",
    "Po wykonaniu wszystkich zadań proszę przesłać wypełniony notatnik przez platformę ELF za pomocą formularza \"Prześlij projekt\" w odpowiedniej sekcji. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresja liniowa wieloraka\n",
    "\n",
    "Rzadko kiedy zdarza się taka sytuacja, że zależność opisuje się na podstawie tylko jednej zmiennej. Z reguły na wynik zmiennej objaśnianej ($y$) ma wpły więcej różnych cech. Przykładowo, na cenę samochodu ma wpływ rok produkcji, przebieg, ilość koni mechanicznych itp. Dlatego właśnie jest naturalna potrzeba rozwinięcia algorytmu regresji liniowej z jedną cechą na większą ilość cech.\n",
    "\n",
    "Algorytm, który implementowaliśmy w poprzednim zadaniu jest szczególnym przypadkiem regresji liniowej, ale może zostać on w łatwy sposób uogólniony. Mechanizmy, które poznaliśmy wcześniej takie jak obliczanie funkcji błędu, pochodnych cząstkowych, w dalszym ciągu są aktualne. Trzeba jedynie uwzględnić dodatkowe cechy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 1\n",
    "\n",
    "W zbiorze danych z zarobkami, który wykorzystywany był w poprzednim zadaniu, znajduje się pominięta wcześniej cecha. Wczytaj dane z pliku Salary.csv, tym razem z dwiema zmiennymi objaśniającymi: YearsExperience i Age oraz zmienną objaśnianą Salary. Stwórz wykres 3D przedstawiający dane."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('Salary.csv', sep=',')\n",
    "\n",
    "x = df[\"YearsExperience\"]\n",
    "y = df[\"Age\"]\n",
    "z = df[\"Salary\"]\n",
    "\n",
    "fig = plt.figure(figsize=(10,7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(x, y, z, c='blue', marker='o')\n",
    "ax.set_xlabel('YearsExperience')\n",
    "ax.set_ylabel('Age')\n",
    "ax.set_zlabel('Salary')\n",
    "ax.set_title('3D Scatter Plot')\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 2\n",
    "\n",
    "Przerób algorytm znajdujący się w funkcji _learn_and_fit(x,y)_ w taki sposób, aby uwzględniał dodatkową cechę.\n",
    "Funkcja regresji liniowej przybierze w tym momencie postać:\n",
    "\n",
    "\\begin{equation}\n",
    "f(x^{(i)}) = \\beta_{0} + \\beta_{1}x_1 + \\beta_{2}x_2 = \\beta_{0} + \\beta_{1} YearsExperience + \\beta_{2} Age\n",
    "\\end{equation}\n",
    "\n",
    "Pojawienie się kolejnej cechy wymaga akutalizacji obliczania gradientu. Należy dodatkowo obliczyć pochodną cząstkową względem parametru $\\beta_{2}$, a następnie zaktualizować wartość tego parametru. \n",
    "\n",
    "Obliczenie pochodnej cząstkowej wygląda analogicznie jak w przypadku parametru $\\beta_{1}$.\n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{\\partial SSR}{\\partial \\beta_{2}} = \\frac{1}{n} \\sum^{n}_{i=1} (f(x^{(i)}) - y^{(i)})x_{1}^{(i)}\n",
    "\\end{equation}\n",
    "\n",
    "Aktualizacja wartości współczynnika również jest analogiczna.\n",
    "\n",
    "\\begin{equation}\n",
    "    \\beta_{2} = \\beta_{2} - \\alpha \\frac{\\partial SSR}{\\partial \\beta_{2}} \n",
    "\\end{equation}\n",
    "\n",
    "_Uwaga: Zastanów się, w jaki sposób zaimplementować obługę kolejnych cech, tak aby po pojawieniu się 3 cechy nie trzeba było modyfikować algorytmu._"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import random\n",
    "from typing import Tuple, List\n",
    "\n",
    "def initialize_coefficients(n: int = 2, alpha = None) -> Tuple[float, np.ndarray]:\n",
    "    if alpha is None:\n",
    "        alpha = random.random()\n",
    "\n",
    "    return alpha, np.array([random.random() for _ in range(n)])\n",
    "\n",
    "\n",
    "def calculate_regression_function(X: np.ndarray, betas: np.ndarray) -> np.ndarray:\n",
    "    return X @ betas\n",
    "\n",
    "\n",
    "def calculate_error(predictions: np.ndarray, y: np.ndarray, betas: np.ndarray) -> float:\n",
    "    m = y.shape[0]\n",
    "    return (np.sum((predictions - y)**2))/(2*m)\n",
    "\n",
    "\n",
    "def calculate_gradient(predictions: np.ndarray, X: np.ndarray, y: np.ndarray, betas: np.ndarray) -> np.ndarray:\n",
    "    m = y.shape[0]\n",
    "    diff = predictions - y\n",
    "    return (X.T @ diff)/m\n",
    "\n",
    "def update_regression_coefficients(X: np.ndarray, y: np.ndarray, betas: np.ndarray, alpha: float) -> np.ndarray:\n",
    "    gradients = calculate_gradient(\n",
    "        calculate_regression_function(X,betas),\n",
    "        X,\n",
    "        y,\n",
    "        betas)\n",
    "    return betas - alpha * gradients"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "'''\n",
    "input:\n",
    "X - wartości zmiennych objaśniających YearsExperience oraz Age dla wszystkich obserwacji\n",
    "y - wartości zmiennej objaśnianej Salary dla wszystkich obserwacji\n",
    "\n",
    "output:\n",
    "b0: [] - lista z współczynnikami beta_0 w każdej z epok\n",
    "betas: [] - lista z współczynnikami beta_1, beta_2 w każdej z epok\n",
    "error: [] - lista z błędem w każdej epoce\n",
    "'''\n",
    "def learn_and_fit(X: np.ndarray, y: np.ndarray, alpha=0.1, epochs=100) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    X = (X - np.mean(X)) / np.std(X)\n",
    "    y = (y - np.mean(y)) / np.std(y)\n",
    "\n",
    "    # Add a column of ones for the bias (beta_0)\n",
    "    X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "\n",
    "\n",
    "    errors = []\n",
    "    b0 = []\n",
    "    betas = []\n",
    "\n",
    "    alpha , betas_values = initialize_coefficients(n=X.shape[1] ,alpha=alpha)\n",
    "    tolerance = 1e-4\n",
    "\n",
    "    for i in range(epochs) :\n",
    "        predictions = calculate_regression_function(X, betas_values)\n",
    "        error = calculate_error(predictions, y, betas_values)\n",
    "        errors.append(error)\n",
    "        betas_values = update_regression_coefficients(X, y, betas_values, alpha)\n",
    "        b0.append(betas_values[0].copy())\n",
    "        betas.append(betas_values[1:].copy())\n",
    "\n",
    "        if i > 0 and abs(errors[-1] - errors[-2]) < tolerance:\n",
    "            print(f\"Stop at epoch {i}, error change < {tolerance}\")\n",
    "            break\n",
    "\n",
    "    return np.array(b0), np.array(betas), np.array(errors)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('Salary.csv', sep=',')\n",
    "\n",
    "xx = df[[\"YearsExperience\", \"Age\"]]\n",
    "y = df[\"Salary\"]\n",
    "print(np.array(xx))\n",
    "b0s, all_betas, errors = learn_and_fit(xx, y, alpha=0.01, epochs=200)\n",
    "print(f\"b0s: {b0s}\\n allbetas: {all_betas} \\n errors: {errors}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 3\n",
    "\n",
    "Do stworzonego z zadaniu 1 wykresu dodaj płaszczyznę regresji. Stwórz 3 wykresy przedstawiające jak zmieniała się funkcja regresji na przestrzeni epok (pierwsza, środkowa, ostatnia epoka)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "# Normalize input data (if not already normalized)\n",
    "xx = (xx - np.mean(xx, axis=0)) / np.std(xx, axis=0)\n",
    "z = (y - np.mean(y, axis=0)) / np.std(y, axis=0)\n",
    "\n",
    "# Generate surface grid\n",
    "x_surf, y_surf = np.meshgrid(\n",
    "    np.linspace(xx.iloc[:, 0].min(), xx.iloc[:, 0].max(), 100),\n",
    "    np.linspace(xx.iloc[:, 1].min(), xx.iloc[:, 1].max(), 100)\n",
    ")\n",
    "\n",
    "# Calculate predicted z values (regression plane)\n",
    "z_surf = b0s[-1] + all_betas[-1][0] * x_surf + all_betas[-1][1] * y_surf\n",
    "\n",
    "# Create plot\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add regression surface\n",
    "fig.add_trace(go.Surface(\n",
    "    x=x_surf,\n",
    "    y=y_surf,\n",
    "    z=z_surf,\n",
    "    colorscale='Blues',\n",
    "    opacity=0.6,\n",
    "    name='Regression Plane',\n",
    "    showscale=False\n",
    "))\n",
    "\n",
    "# Add scatter plot (data points)\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=xx.iloc[:, 0],\n",
    "    y=xx.iloc[:, 1],\n",
    "    z=z,\n",
    "    mode='markers',\n",
    "    marker=dict(size=5, color='red'),\n",
    "    name='Data Points'\n",
    "))\n",
    "\n",
    "# Layout settings\n",
    "fig.update_layout(\n",
    "    title='3D Regression Plane with Data Points (Plotly)',\n",
    "    scene=dict(\n",
    "        xaxis_title='YearsExperience',\n",
    "        yaxis_title='Age',\n",
    "        zaxis_title='Salary'\n",
    "    ),\n",
    "    width=800,\n",
    "    height=700\n",
    ")\n",
    "\n",
    "fig.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 4\n",
    "\n",
    "W sytuacji, w której zbiór danych zawiera więcej zmiennych objaśniających niż 2, niemożliwym staje się wizualizacja prostej regresji i ocena w taki sposób stworzonego modelu. Bardzo przydatnym rozwiązaniem jest wtedy stworzenie wykresu błędów regresji. Jeśli wartości błędu spadają wraz z kolejnymi epokami, oznacza to, że jesteśmy na dobrej drodze, a nasz algorytm działa poprawnie. Celem tego zadania będzie stworzenie finalnego modelu regresji liniowej, który będzie przyjmował dowolną liczbę zmiennych objaśniających.\n",
    "\n",
    "Na podstawie wcześniejszych implementacji, stwórz implementację funkcji *learn_and_fit_multi(X, y)*, która będzie przyjmować zbiór wejściowy z dowolną ilością kolum (cech). Dla takiego zbioru zbioru danych ma zostać stworzony model regresji. Funkcja podobnie jak wcześniej, ma zwracać współczynniki oraz wartość błędu w każdej epoce. \n",
    "\n",
    "W notebooku z opisem regresji liniowej przedstawione zostały wzory na ogólą postać regresji. Przeanalizuj je jeszcze raz i postaraj się je zaimplementować.\n",
    "\n",
    "Wczytaj zestaw danych *multi_variable_regression.csv* z katalogu datasets. Dane wygenerowane zostały w taki sposób, że są wysoce liniowo zależne. Wartość błędu dla nauczonego modelu powinna być w takim przypadku niewielka. Przetestuj na wczytanym zbiorze swój algorytm."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"multi_variable_regression.csv\")\n",
    "\n",
    "# Algorithm for multi variable regression has been implemented in task 2.\n",
    "xx = df.iloc[:, :-2]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "b0s, all_betas, errors = learn_and_fit(xx, y, alpha=0.01, epochs=200)\n",
    "print(f\"errors: {errors}\")\n",
    "print(f\"{errors.shape}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 5\n",
    "\n",
    "Stwórz wykres przedstawiający zmianę błędu regresji w kolejnych epokach. Napisz co można na jego podstawie wywnioskować."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(len(errors)), errors, marker='o', linestyle='-', markersize=2)\n",
    "plt.title(\"Regression Error chart\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Error (Loss)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 6\n",
    "\n",
    "W jaki sposób współczynnik alpha wpływa na działania algorytmu? Przeprowadź eksperyment dla minimum trzech różnych wartości tego parametru. Sformułuj wnioski. Jak zmiana parametru wpłynęła na ilość epok w algorytmie? Jak zmieniła się funkcja regresji?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df = pd.read_csv(\"multi_variable_regression.csv\")\n",
    "\n",
    "# Algorithm for multi variable regression has been implemented in task 2.\n",
    "xx = df.iloc[:, :-2]\n",
    "y = df.iloc[:, -1]\n",
    "alpha_list = [0.001, 0.01, 0.1, 0.5, 1]\n",
    "\n",
    "for alpha in alpha_list:\n",
    "    b0s, all_betas, errors = learn_and_fit(xx, y, alpha=alpha, epochs=300)\n",
    "    print(f\"alpha: {alpha}\")\n",
    "    print(f\"error: {errors[-1]}\")\n",
    "    print(f\"epochs: {errors.shape[0]}\")\n",
    "    plt.plot(errors, label=f'alpha={alpha}')\n",
    "plt.legend()\n",
    "plt.title(\"The influence of alpha coefficient on errors in epochs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.show()\n",
    "\n",
    "# As we can observe, alpha >= 0.01 gives similar effect regarding error value, but higher alpha => less number of epochs to train."
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Porównaj czas działania algorytmu we własnej implementacji oraz implementacji z biblioteki Sklearn."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"multi_variable_regression.csv\")\n",
    "xx = df.iloc[:, :-2]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "start_time = time.time()\n",
    "for i in range(1000):\n",
    "    b0, betas, errors = learn_and_fit(xx, y, alpha=0.01, epochs=200)\n",
    "my_algorithm_time = time.time() - start_time\n",
    "\n",
    "# scikit-learn\n",
    "xx = (xx - np.mean(xx, axis=0)) / np.std(xx, axis=0)\n",
    "y = (y - np.mean(y, axis=0)) / np.std(y, axis=0)\n",
    "\n",
    "model = LinearRegression()\n",
    "start_time = time.time()\n",
    "for i in range(1000):\n",
    "    model.fit(xx, y)\n",
    "sklearn_time = time.time() - start_time\n",
    "\n",
    "plt.plot(errors)\n",
    "plt.title(\"Error per epoch - my implementation\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"My algorithm - time: {my_algorithm_time:.4f} sec\")\n",
    "print(f\"Scikit-learn - time: {sklearn_time:.4f} sec\")\n",
    "\n",
    "# MSE error\n",
    "y_pred = model.predict(xx)\n",
    "error_sklearn = np.mean((y_pred - y) ** 2)\n",
    "print(f\"Error for scikit-learn: {error_sklearn:.4f}\")\n",
    "print(f\"Error for my implementation: {errors[-1]:.4f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
